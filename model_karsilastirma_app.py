import os
import time
import math
from datetime import datetime
from dataclasses import dataclass, field
from typing import Dict, Tuple, List, Optional

import cv2
import numpy as np
import streamlit as st
from ultralytics import YOLO
import mediapipe as mp


# ===========================================================
# GENEL SABÄ°TLER VE AYARLAR
# ===========================================================

# Model isimleri ve dosya yollarÄ± (n ve s)
MODEL_CONFIGS = {
    "yolo11n": {
        "pt": "yolo11n.pt",
        "engine": "yolo11n.engine",
        "label": "YOLO11n (nano)"
    },
    "yolo11s": {
        "pt": "yolo11s.pt",
        "engine": "yolo11s.engine",
        "label": "YOLO11s (small)"
    }
}

# Ä°hlal ve takip ayarlarÄ±
DEVICE = 0                     # GPU id
CONF_THRESH = 0.4              # YOLO gÃ¼ven eÅŸiÄŸi
IOU_TRACK_THRESH = 100         # Centroid tracker max mesafe (piksel)
STILLNESS_SECONDS = 10.0       # Hareketsizlik ihlali eÅŸiÄŸi (sn)
EYE_CLOSED_SECONDS = 10.0      # GÃ¶z kapalÄ±lÄ±ÄŸÄ± ihlali eÅŸiÄŸi (sn)
MOVEMENT_PIXEL_THRESHOLD = 20  # Hareketsizlik iÃ§in merkez hareket eÅŸiÄŸi (piksel)
EAR_THRESHOLD = 0.21           # GÃ¶z kapalÄ± iÃ§in EAR eÅŸiÄŸi
OUTPUT_REPORT_DIR = "raporlar" # RaporlarÄ±n kaydedileceÄŸi klasÃ¶r


# ===========================================================
# BASÄ°T ID TAKÄ°PÃ‡Ä° (CENTROID TRACKER)
# ===========================================================

@dataclass
class Track:
    """Her bir kiÅŸi (takip edilen nesne) iÃ§in ID ve bbox bilgisi tutar."""
    track_id: int
    bbox: Tuple[int, int, int, int]
    last_update_time: float = field(default_factory=time.time)


class CentroidTracker:
    """
    Ã‡ok basit centroid tabanlÄ± takip:
    - Her karede gelen bounding box'larÄ±, bir Ã¶nceki karedeki track'lerle
      merkez mesafesine gÃ¶re eÅŸleÅŸtirir.
    - Her kiÅŸiye benzersiz bir track_id atar.
    """

    def __init__(self, max_distance: float = IOU_TRACK_THRESH, max_lost_time: float = 1.0):
        self.next_id = 0
        self.tracks: Dict[int, Track] = {}
        self.max_distance = max_distance
        self.max_lost_time = max_lost_time

    @staticmethod
    def _center_of_box(bbox: Tuple[int, int, int, int]) -> Tuple[float, float]:
        """Verilen bounding box'Ä±n merkez noktasÄ±nÄ± hesaplar."""
        x1, y1, x2, y2 = bbox
        return (x1 + x2) / 2.0, (y1 + y2) / 2.0

    def update(self, detections: List[Tuple[int, int, int, int]]) -> Dict[int, Tuple[int, int, int, int]]:
        """
        Yeni tespitlere gÃ¶re track'leri gÃ¼nceller ve her birine ID atar.

        :param detections: Her biri (x1, y1, x2, y2) bounding box listesi
        :return: track_id -> bbox sÃ¶zlÃ¼ÄŸÃ¼
        """
        current_time = time.time()
        assigned_tracks: Dict[int, Tuple[int, int, int, int]] = {}

        # Tespit yoksa sadece zaman aÅŸÄ±mÄ± kontrolÃ¼ yap
        if not detections:
            self._cleanup(current_time)
            return {tid: t.bbox for tid, t in self.tracks.items()}

        track_ids = list(self.tracks.keys())
        track_centers = [self._center_of_box(self.tracks[tid].bbox) for tid in track_ids]
        used_detections = set()

        # Her yeni tespit iÃ§in en yakÄ±n track'i bul
        for det_idx, det_bbox in enumerate(detections):
            det_center = self._center_of_box(det_bbox)
            best_track_id = None
            best_dist = float("inf")

            for tid, t_center in zip(track_ids, track_centers):
                if tid in assigned_tracks:
                    continue
                dist = math.dist(det_center, t_center)
                if dist < best_dist and dist < self.max_distance:
                    best_dist = dist
                    best_track_id = tid

            if best_track_id is not None:
                self.tracks[best_track_id].bbox = det_bbox
                self.tracks[best_track_id].last_update_time = current_time
                assigned_tracks[best_track_id] = det_bbox
                used_detections.add(det_idx)

        # EÅŸleÅŸmeyen her tespit iÃ§in yeni track oluÅŸtur
        for det_idx, det_bbox in enumerate(detections):
            if det_idx in used_detections:
                continue
            new_id = self.next_id
            self.next_id += 1
            self.tracks[new_id] = Track(track_id=new_id, bbox=det_bbox, last_update_time=current_time)
            assigned_tracks[new_id] = det_bbox

        # Eski, kaybolmuÅŸ track'leri temizle
        self._cleanup(current_time)

        return {tid: self.tracks[tid].bbox for tid in self.tracks.keys()}

    def _cleanup(self, current_time: float):
        """Uzun sÃ¼re gÃ¼ncellenmeyen (kayÄ±p) track'leri siler."""
        to_delete = []
        for tid, t in self.tracks.items():
            if current_time - t.last_update_time > self.max_lost_time:
                to_delete.append(tid)
        for tid in to_delete:
            del self.tracks[tid]


# ===========================================================
# KÄ°ÅÄ° DURUM TAKÄ°BÄ° VE Ä°HLAL EPÄ°ZODLARI
# ===========================================================

@dataclass
class PersonState:
    """
    Her kiÅŸi iÃ§in:
    - referans merkez (hareketsizlik iÃ§in),
    - hareketsizlik baÅŸlangÄ±Ã§ zamanÄ±,
    - gÃ¶z kapalÄ±lÄ±k baÅŸlangÄ±Ã§ zamanÄ±,
    - son EAR deÄŸeri,
    gibi bilgileri tutar.
    """
    track_id: int
    ref_centroid: Tuple[float, float]
    still_start_time: Optional[float] = None
    eye_closed_start_time: Optional[float] = None
    last_ear: float = 0.0


@dataclass
class ViolationEpisode:
    """
    Bir ihlal epizodunu temsil eder:
    - tÃ¼r (Hareketsizlik / GÃ¶z KapalÄ±),
    - baÅŸlangÄ±Ã§ saniyesi,
    - bitiÅŸ saniyesi,
    - toplam sÃ¼re (sn).
    """
    violation_type: str
    start_sec: float
    end_sec: float

    @property
    def duration(self) -> float:
        return max(0.0, self.end_sec - self.start_sec)


class ViolationManager:
    """
    TÃ¼m kiÅŸiler iÃ§in ihlalleri takip eder ve
    global ihlal epizodlarÄ±nÄ± (baÅŸlangÄ±Ã§/bitiÅŸ saniyeleri) kaydeder.
    """

    def __init__(self):
        self.person_states: Dict[int, PersonState] = {}

        # Global ihlal durumlarÄ± (her tÃ¼r iÃ§in ayrÄ±)
        self.global_still_active = False
        self.global_eye_active = False
        self.global_still_start_sec: Optional[float] = None
        self.global_eye_start_sec: Optional[float] = None

        # Biten ihlal epizodlarÄ±
        self.episodes: List[ViolationEpisode] = []

    @staticmethod
    def _center_of_box(bbox: Tuple[int, int, int, int]) -> Tuple[float, float]:
        x1, y1, x2, y2 = bbox
        return (x1 + x2) / 2.0, (y1 + y2) / 2.0

    def update_tracks(self, track_boxes: Dict[int, Tuple[int, int, int, int]], current_sec: float):
        """
        Her karede, aktif track listesine gÃ¶re:
        - yeni PersonState'ler oluÅŸturur,
        - hareketsizlik sÃ¼relerini gÃ¼nceller,
        - kaybolan kiÅŸileri siler.
        """
        existing_ids = set(self.person_states.keys())
        current_ids = set(track_boxes.keys())

        # Yeni track'ler
        for tid in current_ids - existing_ids:
            centroid = self._center_of_box(track_boxes[tid])
            self.person_states[tid] = PersonState(track_id=tid, ref_centroid=centroid)

        # Hareketsizlik takibi
        for tid in current_ids:
            bbox = track_boxes[tid]
            centroid = self._center_of_box(bbox)
            state = self.person_states[tid]

            dist = math.dist(centroid, state.ref_centroid)
            if dist < MOVEMENT_PIXEL_THRESHOLD:
                if state.still_start_time is None:
                    state.still_start_time = current_sec
            else:
                state.ref_centroid = centroid
                state.still_start_time = None

        # Kaybolan track'leri sil
        for tid in existing_ids - current_ids:
            del self.person_states[tid]

    def update_eye_state(self, track_id: int, ear: float, current_sec: float):
        """
        MediaPipe FaceMesh'ten gelen EAR deÄŸerine gÃ¶re
        ilgili kiÅŸide gÃ¶z kapalÄ±lÄ±k sÃ¼resini gÃ¼nceller.
        """
        if track_id not in self.person_states:
            return

        state = self.person_states[track_id]
        state.last_ear = ear

        if ear < EAR_THRESHOLD:
            if state.eye_closed_start_time is None:
                state.eye_closed_start_time = current_sec
        else:
            state.eye_closed_start_time = None

    def compute_global_violations(self, current_sec: float):
        """
        TÃ¼m kiÅŸiler iÃ§in:
        - Hareketsizlik ve gÃ¶z kapalÄ±lÄ±k sÃ¼resini kontrol eder,
        - global ihlal durumunu gÃ¼nceller,
        - ihlal epizodlarÄ±nÄ± (baÅŸlangÄ±Ã§/bitiÅŸ saniyeleriyle) kaydeder.
        """
        # En az bir kiÅŸide ihlal var mÄ±?
        any_still_violation = False
        any_eye_violation = False

        for state in self.person_states.values():
            # Hareketsizlik kontrolÃ¼
            if state.still_start_time is not None:
                if current_sec - state.still_start_time >= STILLNESS_SECONDS:
                    any_still_violation = True

            # GÃ¶z kapalÄ±lÄ±k kontrolÃ¼
            if state.eye_closed_start_time is not None:
                if current_sec - state.eye_closed_start_time >= EYE_CLOSED_SECONDS:
                    any_eye_violation = True

        # --- Hareketsizlik epizod yÃ¶netimi ---
        if any_still_violation:
            if not self.global_still_active:
                # Yeni bir hareketsizlik epizodu baÅŸlÄ±yor
                self.global_still_active = True
                self.global_still_start_sec = current_sec
        else:
            if self.global_still_active:
                # Hareketsizlik epizodu sona erdi â†’ kaydet
                start = self.global_still_start_sec if self.global_still_start_sec is not None else current_sec
                self.episodes.append(ViolationEpisode("Hareketsizlik", start_sec=start, end_sec=current_sec))
                self.global_still_active = False
                self.global_still_start_sec = None

        # --- GÃ¶z kapalÄ±lÄ±k epizod yÃ¶netimi ---
        if any_eye_violation:
            if not self.global_eye_active:
                self.global_eye_active = True
                self.global_eye_start_sec = current_sec
        else:
            if self.global_eye_active:
                start = self.global_eye_start_sec if self.global_eye_start_sec is not None else current_sec
                self.episodes.append(ViolationEpisode("Goz Kapali", start_sec=start, end_sec=current_sec))
                self.global_eye_active = False
                self.global_eye_start_sec = None

    def finalize(self, last_sec: float):
        """
        Video bittiÄŸinde, hala aÃ§Ä±k olan epizodlar varsa
        son saniyeyi bitiÅŸ olarak kabul edip kapatÄ±r.
        """
        if self.global_still_active and self.global_still_start_sec is not None:
            self.episodes.append(
                ViolationEpisode("Hareketsizlik", start_sec=self.global_still_start_sec, end_sec=last_sec)
            )
        if self.global_eye_active and self.global_eye_start_sec is not None:
                self.episodes.append(
                    ViolationEpisode("Goz Kapali", start_sec=self.global_eye_start_sec, end_sec=last_sec)
                )


# ===========================================================
# EAR / MEDIAPIPE FACE MESH
# ===========================================================

mp_face_mesh = mp.solutions.face_mesh

LEFT_EYE_IDX = [33, 160, 158, 133, 153, 144]
RIGHT_EYE_IDX = [362, 385, 387, 263, 373, 380]
NOSE_IDX = 1  # yÃ¼zÃ¼ vÃ¼cut kutusuna baÄŸlamak iÃ§in basit burun noktasÄ±


def euclidean_distance(p1: Tuple[float, float], p2: Tuple[float, float]) -> float:
    return math.sqrt((p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2)


def eye_aspect_ratio(eye_points: List[Tuple[float, float]]) -> float:
    """
    EAR hesabÄ±:
        EAR = (||p2 - p6|| + ||p3 - p5||) / (2 * ||p1 - p4||)
    GÃ¶z kapandÄ±kÃ§a vertical mesafeler kÃ¼Ã§Ã¼lÃ¼r â†’ EAR dÃ¼ÅŸer.
    """
    if len(eye_points) != 6:
        return 0.0
    p1, p2, p3, p4, p5, p6 = eye_points
    vertical_1 = euclidean_distance(p2, p6)
    vertical_2 = euclidean_distance(p3, p5)
    horizontal = euclidean_distance(p1, p4)
    if horizontal == 0:
        return 0.0
    ear = (vertical_1 + vertical_2) / (2.0 * horizontal)
    return ear


def compute_ear_for_faces(
    frame,
    face_landmarks_list,
    track_boxes: Dict[int, Tuple[int, int, int, int]],
    violation_manager: ViolationManager,
    current_sec: float,
):
    """
    - Her yÃ¼z iÃ§in sol ve saÄŸ gÃ¶z EAR deÄŸerini hesaplar.
    - Burun noktasÄ±nÄ± kullanarak yÃ¼zÃ¼ ilgili vÃ¼cut kutusuna (track_id) baÄŸlar.
    - EAR deÄŸerini ViolationManager'a iletir.
    """
    h, w, _ = frame.shape

    for face_landmarks in face_landmarks_list:
        coords = []
        for lm in face_landmarks.landmark:
            x_px = int(lm.x * w)
            y_px = int(lm.y * h)
            coords.append((x_px, y_px))

        left_eye = [coords[i] for i in LEFT_EYE_IDX]
        right_eye = [coords[i] for i in RIGHT_EYE_IDX]

        left_ear = eye_aspect_ratio(left_eye)
        right_ear = eye_aspect_ratio(right_eye)
        ear = (left_ear + right_ear) / 2.0

        nose_x, nose_y = coords[NOSE_IDX]
        assigned_track_id = None
        for tid, bbox in track_boxes.items():
            x1, y1, x2, y2 = bbox
            if x1 <= nose_x <= x2 and y1 <= nose_y <= y2:
                assigned_track_id = tid
                break

        if assigned_track_id is not None:
            violation_manager.update_eye_state(assigned_track_id, ear, current_sec)


# ===========================================================
# YOLO + TENSORRT YÃœKLEME/OLUÅTURMA
# ===========================================================

def load_or_build_trt_model(model_key: str) -> YOLO:
    """
    Belirtilen model iÃ§in:
    - .engine varsa onu yÃ¼kler.
    - Yoksa .pt'den TensorRT FP16 engine Ã¼retir, sonra onu yÃ¼kler.
    """
    cfg = MODEL_CONFIGS[model_key]
    pt_path = cfg["pt"]
    engine_path = cfg["engine"]

    if os.path.exists(engine_path):
        st.info(f"{cfg['label']} iÃ§in mevcut TensorRT engine bulundu: {engine_path}")
        return YOLO(engine_path)

    # Engine yoksa, Ã¶nce PT modelini yÃ¼kle (gerekirse indirir)
    if not os.path.exists(pt_path):
        st.warning(f"{pt_path} bulunamadÄ±, Ultralytics Ã¼zerinden indirilecek.")
        model = YOLO(pt_path)  # isimle Ã§aÄŸÄ±rmak indirir
    else:
        model = YOLO(pt_path)

    st.info(f"{cfg['label']} iÃ§in TensorRT FP16 engine Ã¼retiliyor (ilk seferde sÃ¼rebilir)...")
    model.export(format="engine", half=True, device=DEVICE)

    if not os.path.exists(engine_path):
        raise FileNotFoundError(f"{engine_path} oluÅŸturulamadÄ±.")

    st.success(f"{cfg['label']} TensorRT engine oluÅŸturuldu: {engine_path}")
    return YOLO(engine_path)


# ===========================================================
# VÄ°DEOYU BÄ°R MODELLE ANALÄ°Z ETME (ANA Ä°ÅLEMCÄ° FONKSÄ°YON)
# ===========================================================

def analyze_video_with_model(video_path: str, model_key: str) -> Tuple[List[ViolationEpisode], float]:
    """
    Verilen video dosyasÄ±nÄ± tek bir YOLO modeli ile analiz eder.
    - Hareketsizlik ve gÃ¶z kapalÄ±lÄ±k ihlallerini zaman damgalÄ± olarak takip eder.
    - Biten ihlal epizodlarÄ±nÄ± (start, end, duration) dÃ¶ndÃ¼rÃ¼r.
    - Ortalama FPS (iÅŸleme hÄ±zÄ±) dÃ¶ndÃ¼rÃ¼r.
    """
    model = load_or_build_trt_model(model_key)
    cfg = MODEL_CONFIGS[model_key]

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise RuntimeError("Video aÃ§Ä±lamadÄ±.")

    fps_video = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    tracker = CentroidTracker()
    violation_manager = ViolationManager()

    face_mesh = mp_face_mesh.FaceMesh(
        static_image_mode=False,
        max_num_faces=5,
        refine_landmarks=True,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5,
    )

    # FPS Ã¶lÃ§Ã¼mÃ¼ iÃ§in
    total_time_processing = 0.0
    processed_frames = 0

    progress_bar = st.progress(0)
    status_text = st.empty()

    frame_index = 0
    last_sec = 0.0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        # Video FPS'ine gÃ¶re bu frame'in saniyesini hesapla
        current_sec = frame_index / fps_video if fps_video > 0 else 0.0
        last_sec = current_sec
        frame_index += 1

        start_time = time.time()

        h, w = frame.shape[:2]

        # 1) YOLO ile kiÅŸi tespiti (sadece "person" sÄ±nÄ±fÄ±)
        yolo_results = model(
            frame,
            conf=CONF_THRESH,
            classes=[0],  # person
            device=DEVICE,
            verbose=False
        )

        detections: List[Tuple[int, int, int, int]] = []
        if len(yolo_results) > 0:
            result = yolo_results[0]
            if result.boxes is not None:
                for box in result.boxes:
                    x1, y1, x2, y2 = box.xyxy[0].tolist()
                    x1 = int(max(0, x1))
                    y1 = int(max(0, y1))
                    x2 = int(min(w - 1, x2))
                    y2 = int(min(h - 1, y2))
                    detections.append((x1, y1, x2, y2))

        # 2) Centroid tracker ile ID takibi
        track_boxes = tracker.update(detections)
        violation_manager.update_tracks(track_boxes, current_sec)

        # 3) MediaPipe FaceMesh + EAR
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        face_results = face_mesh.process(frame_rgb)
        if face_results.multi_face_landmarks:
            compute_ear_for_faces(
                frame,
                face_results.multi_face_landmarks,
                track_boxes,
                violation_manager,
                current_sec,
            )

        # 4) Global ihlal durumlarÄ±nÄ± gÃ¼ncelle
        violation_manager.compute_global_violations(current_sec)

        # FPS Ã¶lÃ§Ã¼mÃ¼
        end_time = time.time()
        total_time_processing += (end_time - start_time)
        processed_frames += 1

        # Streamlit progress bar gÃ¼ncelle
        if total_frames > 0:
            progress = min(1.0, frame_index / total_frames)
        else:
            progress = 0.0
        progress_bar.progress(progress)
        status_text.text(f"{cfg['label']} - Ä°ÅŸlenen kare: {frame_index}/{total_frames} (t ~ {current_sec:.1f} sn)")

    # Video bittiÄŸinde aÃ§Ä±k epizodlarÄ± kapat
    violation_manager.finalize(last_sec)

    cap.release()
    face_mesh.close()

    avg_fps = processed_frames / total_time_processing if total_time_processing > 0 else 0.0
    progress_bar.empty()
    status_text.text(f"{cfg['label']} analizi tamamlandÄ±. Ortalama FPS: {avg_fps:.2f}")

    return violation_manager.episodes, avg_fps


# ===========================================================
# RAPOR OLUÅTURMA
# ===========================================================

def save_report_csv(
    report_name: str,
    model_results: Dict[str, Dict[str, object]],
) -> str:
    """
    Verilen model sonuÃ§larÄ±yla (ihlaller + fps) CSV raporu oluÅŸturur.

    model_results:
      {
        "yolo11n": {
            "episodes": [ViolationEpisode, ...],
            "fps": 12.3
        },
        "yolo11s": {
            "episodes": [...],
            "fps": 18.7
        }
      }
    """
    os.makedirs(OUTPUT_REPORT_DIR, exist_ok=True)
    timestamp_str = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    filename = f"{report_name}_{timestamp_str}.csv"
    filepath = os.path.join(OUTPUT_REPORT_DIR, filename)

    # TÃ¼rkÃ§e Windows/Excel'de genelde CSV ayÄ±racÄ± ";" olduÄŸu iÃ§in
    # burada da noktalÄ± virgÃ¼l kullanÄ±yoruz. SayÄ±larÄ± da virgÃ¼llÃ¼
    # ondalÄ±k formatta yazarak Excel'de daha okunaklÄ± hale getiriyoruz.
    sep = ";"

    lines = []
    # BaÅŸlÄ±k satÄ±rÄ±
    lines.append(
        sep.join(
            [
                "model",
                "ihlal_turu",
                "baslangic_saniyesi",
                "bitis_saniyesi",
                "toplam_sure_saniye",
            ]
        )
    )

    # Her model iÃ§in ihlalleri yaz
    for model_key, data in model_results.items():
        label = MODEL_CONFIGS[model_key]["label"]
        episodes: List[ViolationEpisode] = data.get("episodes", [])
        for ep in episodes:
            start_str = f"{ep.start_sec:.2f}".replace(".", ",")
            end_str = f"{ep.end_sec:.2f}".replace(".", ",")
            dur_str = f"{ep.duration:.2f}".replace(".", ",")
            lines.append(
                sep.join(
                    [
                        label,
                        ep.violation_type,
                        start_str,
                        end_str,
                        dur_str,
                    ]
                )
            )

    # Sonuna FPS Ã¶zeti ekleyelim (ayrÄ± blok)
    lines.append("")
    lines.append(sep.join(["model", "ortalama_fps"]))
    for model_key, data in model_results.items():
        label = MODEL_CONFIGS[model_key]["label"]
        fps = data.get("fps", 0.0)
        fps_str = f"{fps:.2f}".replace(".", ",")
        lines.append(sep.join([label, fps_str]))

    # Excel'in UTF-8'i doÄŸru tanÄ±yabilmesi iÃ§in BOM ekleyen utf-8-sig kullanÄ±yoruz.
    with open(filepath, "w", encoding="utf-8-sig") as f:
        f.write("\n".join(lines))

    return filepath


# ===========================================================
# STREAMLIT ARAYÃœZÃœ
# ===========================================================

def main():
    """
    Streamlit tabanlÄ± gÃ¶rsel arayÃ¼z:
    - KullanÄ±cÄ±dan .mp4 video alÄ±r.
    - Hangi modeli/leri kullanacaÄŸÄ±nÄ± seÃ§tirir.
    - Analiz baÅŸlatÄ±ldÄ±ÄŸÄ±nda ilerleme Ã§ubuÄŸu gÃ¶sterir.
    - Analiz sonunda ihlal epizodlarÄ±nÄ± tablo ve CSV rapor olarak sunar.
    """
    st.set_page_config(page_title="Model KarÅŸÄ±laÅŸtÄ±rma ve Raporlama Sistemi", layout="wide")
    st.title("ğŸ“Š Model KarÅŸÄ±laÅŸtÄ±rma ve Raporlama Sistemi")
    st.markdown("**YOLO11n vs YOLO11s - Uyku ve GÃ¼venlik Ä°hlal Analizi (TensorRT FP16)**")

    # Video yÃ¼kleme
    uploaded_file = st.file_uploader("Analiz edilecek .mp4 videoyu seÃ§in", type=["mp4"])

    # Model seÃ§imi
    model_options = ["yolo11n", "yolo11s"]
    selected_models = st.multiselect(
        "Hangi modellerle analiz yapÄ±lsÄ±n?",
        options=model_options,
        default=model_options,  # varsayÄ±lan: ikisi de
        format_func=lambda k: MODEL_CONFIGS[k]["label"],
    )

    if not uploaded_file:
        st.info("LÃ¼tfen Ã¶nce bir .mp4 video dosyasÄ± yÃ¼kleyin.")
        return

    # YÃ¼klenen dosyayÄ± geÃ§ici bir yere kaydedelim
    temp_video_path = os.path.join("temp_video.mp4")
    with open(temp_video_path, "wb") as f:
        f.write(uploaded_file.read())

    if st.button("Analizi BaÅŸlat"):
        if not selected_models:
            st.warning("En az bir model seÃ§melisiniz.")
            return

        st.write("---")
        st.subheader("ğŸ” Analiz BaÅŸlÄ±yor")

        model_results: Dict[str, Dict[str, object]] = {}

        # Her seÃ§ili model iÃ§in ayrÄ± ayrÄ± analiz
        for m_key in selected_models:
            st.markdown(f"### {MODEL_CONFIGS[m_key]['label']} Analizi")
            episodes, avg_fps = analyze_video_with_model(temp_video_path, m_key)
            model_results[m_key] = {
                "episodes": episodes,
                "fps": avg_fps,
            }

            # Bu model iÃ§in ihlalleri tablo olarak gÃ¶ster
            if episodes:
                # Streamlit tabloda tam olarak 2 ondalÄ±k hane gÃ¶stermek iÃ§in
                # deÄŸerleri string formatÄ±na Ã§eviriyoruz.
                data = {
                    "Ä°hlal TÃ¼rÃ¼": [ep.violation_type for ep in episodes],
                    "BaÅŸlangÄ±Ã§ (sn)": [f"{ep.start_sec:.2f}" for ep in episodes],
                    "BitiÅŸ (sn)": [f"{ep.end_sec:.2f}" for ep in episodes],
                    "SÃ¼re (sn)": [f"{ep.duration:.2f}" for ep in episodes],
                }
                st.table(data)
            else:
                st.info("Bu model iÃ§in ihlal tespit edilmedi.")

            st.write(f"**Ortalama FPS:** {avg_fps:.2f}")
            st.write("---")

        # Her iki model iÃ§in performans karÅŸÄ±laÅŸtÄ±rmasÄ±
        st.subheader("âš–ï¸ Model Performans KarÅŸÄ±laÅŸtÄ±rmasÄ± (Ort. FPS)")
        # Ortalama FPS'leri tabloda da tam 2 ondalÄ±k hane ile gÃ¶stermek iÃ§in
        # string formatÄ±na Ã§eviriyoruz.
        perf_data = {
            "Model": [MODEL_CONFIGS[m]["label"] for m in model_results.keys()],
            "Ortalama FPS": [f"{model_results[m]['fps']:.2f}" for m in model_results.keys()],
        }
        st.table(perf_data)

        # Rapor dosyasÄ±nÄ± oluÅŸtur ve indirme linki ver
        st.subheader("ğŸ“ Rapor OluÅŸturma")
        report_path = save_report_csv("model_karsilastirma_raporu", model_results)
        st.success(f"Rapor oluÅŸturuldu: {report_path}")

        with open(report_path, "rb") as f:
            st.download_button(
                label="Raporu Ä°ndir (.csv)",
                data=f,
                file_name=os.path.basename(report_path),
                mime="text/csv",
            )


if __name__ == "__main__":
    main()

