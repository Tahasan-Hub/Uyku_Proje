import os
import time
import math
from datetime import datetime
from dataclasses import dataclass, field
from typing import Dict, Tuple, List, Optional

import cv2
import numpy as np
import streamlit as st
from ultralytics import YOLO
import mediapipe as mp

from utils.core_logic import (
    CentroidTracker, ViolationManager, ViolationEpisode,
    eye_aspect_ratio, LEFT_EYE_IDX, RIGHT_EYE_IDX, NOSE_IDX
)


# ===========================================================
# GENEL SABÄ°TLER VE AYARLAR
# ===========================================================
# ... (sabitler aynÄ± kalÄ±yor) ...
MODEL_CONFIGS = {
    "yolo11n": {
        "pt": "yolo11n.pt",
        "engine": "yolo11n.engine",
        "label": "YOLO11n (nano)"
    },
    "yolo11s": {
        "pt": "yolo11s.pt",
        "engine": "yolo11s.engine",
        "label": "YOLO11s (small)"
    }
}

# Ä°hlal ve takip ayarlarÄ±
DEVICE = 0                     # GPU id
CONF_THRESH = 0.4              # YOLO gÃ¼ven eÅŸiÄŸi
IOU_TRACK_THRESH = 100         # Centroid tracker max mesafe (piksel)
STILLNESS_SECONDS = 10.0       # Hareketsizlik ihlali eÅŸiÄŸi (sn)
EYE_CLOSED_SECONDS = 10.0      # GÃ¶z kapalÄ±lÄ±ÄŸÄ± ihlali eÅŸiÄŸi (sn)
MOVEMENT_PIXEL_THRESHOLD = 20  # Hareketsizlik iÃ§in merkez hareket eÅŸiÄŸi (piksel)
EAR_THRESHOLD = 0.21           # GÃ¶z kapalÄ± iÃ§in EAR eÅŸiÄŸi
OUTPUT_REPORT_DIR = "raporlar" # RaporlarÄ±n kaydedileceÄŸi klasÃ¶r


# ===========================================================
# EAR / MEDIAPIPE FACE MESH
# ===========================================================

mp_face_mesh = mp.solutions.face_mesh

def compute_ear_for_faces(
    frame,
    face_landmarks_list,
    track_boxes: Dict[int, Tuple[int, int, int, int]],
    violation_manager: ViolationManager,
    current_sec: float,
):
    """
    - Her yÃ¼z iÃ§in sol ve saÄŸ gÃ¶z EAR deÄŸerini hesaplar.
    - Burun noktasÄ±nÄ± kullanarak yÃ¼zÃ¼ ilgili vÃ¼cut kutusuna (track_id) baÄŸlar.
    - EAR deÄŸerini ViolationManager'a iletir.
    """
    h, w, _ = frame.shape

    for face_landmarks in face_landmarks_list:
        coords = []
        for lm in face_landmarks.landmark:
            x_px = int(lm.x * w)
            y_px = int(lm.y * h)
            coords.append((x_px, y_px))

        left_eye = [coords[i] for i in LEFT_EYE_IDX]
        right_eye = [coords[i] for i in RIGHT_EYE_IDX]

        left_ear = eye_aspect_ratio(left_eye)
        right_ear = eye_aspect_ratio(right_eye)
        ear = (left_ear + right_ear) / 2.0

        nose_x, nose_y = coords[NOSE_IDX]
        assigned_track_id = None
        for tid, bbox in track_boxes.items():
            x1, y1, x2, y2 = bbox
            if x1 <= nose_x <= x2 and y1 <= nose_y <= y2:
                assigned_track_id = tid
                break

        if assigned_track_id is not None:
            violation_manager.update_eye_state(assigned_track_id, ear, current_sec)


# ===========================================================
# YOLO + TENSORRT YÃœKLEME/OLUÅTURMA
# ===========================================================

def load_or_build_trt_model(model_key: str) -> YOLO:
# ... (devamÄ± aynÄ±) ...
    """
    Belirtilen model iÃ§in:
    - .engine varsa onu yÃ¼kler.
    - Yoksa .pt'den TensorRT FP16 engine Ã¼retir, sonra onu yÃ¼kler.
    """
    cfg = MODEL_CONFIGS[model_key]
    pt_path = cfg["pt"]
    engine_path = cfg["engine"]

    if os.path.exists(engine_path):
        st.info(f"{cfg['label']} iÃ§in mevcut TensorRT engine bulundu: {engine_path}")
        return YOLO(engine_path)

    # Engine yoksa, Ã¶nce PT modelini yÃ¼kle (gerekirse indirir)
    if not os.path.exists(pt_path):
        st.warning(f"{pt_path} bulunamadÄ±, Ultralytics Ã¼zerinden indirilecek.")
        model = YOLO(pt_path)  # isimle Ã§aÄŸÄ±rmak indirir
    else:
        model = YOLO(pt_path)

    st.info(f"{cfg['label']} iÃ§in TensorRT FP16 engine Ã¼retiliyor (ilk seferde sÃ¼rebilir)...")
    model.export(format="engine", half=True, device=DEVICE)

    if not os.path.exists(engine_path):
        raise FileNotFoundError(f"{engine_path} oluÅŸturulamadÄ±.")

    st.success(f"{cfg['label']} TensorRT engine oluÅŸturuldu: {engine_path}")
    return YOLO(engine_path)


# ===========================================================
# VÄ°DEOYU BÄ°R MODELLE ANALÄ°Z ETME (ANA Ä°ÅLEMCÄ° FONKSÄ°YON)
# ===========================================================

def analyze_video_with_model(video_path: str, model_key: str) -> Tuple[List[ViolationEpisode], float]:
    """
    Verilen video dosyasÄ±nÄ± tek bir YOLO modeli ile analiz eder.
    - Hareketsizlik ve gÃ¶z kapalÄ±lÄ±k ihlallerini zaman damgalÄ± olarak takip eder.
    - Biten ihlal epizodlarÄ±nÄ± (start, end, duration) dÃ¶ndÃ¼rÃ¼r.
    - Ortalama FPS (iÅŸleme hÄ±zÄ±) dÃ¶ndÃ¼rÃ¼r.
    """
    model = load_or_build_trt_model(model_key)
    cfg = MODEL_CONFIGS[model_key]

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise RuntimeError("Video aÃ§Ä±lamadÄ±.")

    fps_video = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    tracker = CentroidTracker(max_distance=IOU_TRACK_THRESH)
    violation_manager = ViolationManager(
        still_threshold=STILLNESS_SECONDS,
        eye_threshold=EYE_CLOSED_SECONDS,
        movement_threshold=MOVEMENT_PIXEL_THRESHOLD,
        ear_threshold=EAR_THRESHOLD
    )

    face_mesh = mp_face_mesh.FaceMesh(
        static_image_mode=False,
        max_num_faces=5,
        refine_landmarks=True,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5,
    )

    # FPS Ã¶lÃ§Ã¼mÃ¼ iÃ§in
    total_time_processing = 0.0
    processed_frames = 0

    progress_bar = st.progress(0)
    status_text = st.empty()

    frame_index = 0
    last_sec = 0.0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        # Video FPS'ine gÃ¶re bu frame'in saniyesini hesapla
        current_sec = frame_index / fps_video if fps_video > 0 else 0.0
        last_sec = current_sec
        frame_index += 1

        start_time = time.time()

        h, w = frame.shape[:2]

        # 1) YOLO ile kiÅŸi tespiti (sadece "person" sÄ±nÄ±fÄ±)
        yolo_results = model(
            frame,
            conf=CONF_THRESH,
            classes=[0],  # person
            device=DEVICE,
            verbose=False
        )

        detections: List[Tuple[int, int, int, int]] = []
        if len(yolo_results) > 0:
            result = yolo_results[0]
            if result.boxes is not None:
                for box in result.boxes:
                    x1, y1, x2, y2 = box.xyxy[0].tolist()
                    x1 = int(max(0, x1))
                    y1 = int(max(0, y1))
                    x2 = int(min(w - 1, x2))
                    y2 = int(min(h - 1, y2))
                    detections.append((x1, y1, x2, y2))

        # 2) Centroid tracker ile ID takibi
        track_boxes = tracker.update(detections)
        violation_manager.update_tracks(track_boxes, current_sec)

        # 3) MediaPipe FaceMesh + EAR
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        face_results = face_mesh.process(frame_rgb)
        if face_results.multi_face_landmarks:
            compute_ear_for_faces(
                frame,
                face_results.multi_face_landmarks,
                track_boxes,
                violation_manager,
                current_sec,
            )

        # 4) Global ihlal durumlarÄ±nÄ± gÃ¼ncelle
        violation_manager.compute_violations(current_sec)

        # FPS Ã¶lÃ§Ã¼mÃ¼
        end_time = time.time()
        total_time_processing += (end_time - start_time)
        processed_frames += 1

        # Streamlit progress bar gÃ¼ncelle
        if total_frames > 0:
            progress = min(1.0, frame_index / total_frames)
        else:
            progress = 0.0
        progress_bar.progress(progress)
        status_text.text(f"{cfg['label']} - Ä°ÅŸlenen kare: {frame_index}/{total_frames} (t ~ {current_sec:.1f} sn)")

    # Video bittiÄŸinde aÃ§Ä±k epizodlarÄ± kapat
    violation_manager.finalize(last_sec)

    cap.release()
    face_mesh.close()

    avg_fps = processed_frames / total_time_processing if total_time_processing > 0 else 0.0
    progress_bar.empty()
    status_text.text(f"{cfg['label']} analizi tamamlandÄ±. Ortalama FPS: {avg_fps:.2f}")

    return violation_manager.episodes, avg_fps


# ===========================================================
# RAPOR OLUÅTURMA
# ===========================================================

def save_report_csv(
    report_name: str,
    model_results: Dict[str, Dict[str, object]],
) -> str:
    """
    Verilen model sonuÃ§larÄ±yla (ihlaller + fps) CSV raporu oluÅŸturur.

    model_results:
      {
        "yolo11n": {
            "episodes": [ViolationEpisode, ...],
            "fps": 12.3
        },
        "yolo11s": {
            "episodes": [...],
            "fps": 18.7
        }
      }
    """
    os.makedirs(OUTPUT_REPORT_DIR, exist_ok=True)
    timestamp_str = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    filename = f"{report_name}_{timestamp_str}.csv"
    filepath = os.path.join(OUTPUT_REPORT_DIR, filename)

    # TÃ¼rkÃ§e Windows/Excel'de genelde CSV ayÄ±racÄ± ";" olduÄŸu iÃ§in
    # burada da noktalÄ± virgÃ¼l kullanÄ±yoruz. SayÄ±larÄ± da virgÃ¼llÃ¼
    # ondalÄ±k formatta yazarak Excel'de daha okunaklÄ± hale getiriyoruz.
    sep = ";"

    lines = []
    # BaÅŸlÄ±k satÄ±rÄ±
    lines.append(
        sep.join(
            [
                "model",
                "ihlal_turu",
                "baslangic_saniyesi",
                "bitis_saniyesi",
                "toplam_sure_saniye",
            ]
        )
    )

    # Her model iÃ§in ihlalleri yaz
    for model_key, data in model_results.items():
        label = MODEL_CONFIGS[model_key]["label"]
        episodes: List[ViolationEpisode] = data.get("episodes", [])
        for ep in episodes:
            start_str = f"{ep.start_sec:.2f}".replace(".", ",")
            end_str = f"{ep.end_sec:.2f}".replace(".", ",")
            dur_str = f"{ep.duration:.2f}".replace(".", ",")
            lines.append(
                sep.join(
                    [
                        label,
                        ep.violation_type,
                        start_str,
                        end_str,
                        dur_str,
                    ]
                )
            )

    # Sonuna FPS Ã¶zeti ekleyelim (ayrÄ± blok)
    lines.append("")
    lines.append(sep.join(["model", "ortalama_fps"]))
    for model_key, data in model_results.items():
        label = MODEL_CONFIGS[model_key]["label"]
        fps = data.get("fps", 0.0)
        fps_str = f"{fps:.2f}".replace(".", ",")
        lines.append(sep.join([label, fps_str]))

    # Excel'in UTF-8'i doÄŸru tanÄ±yabilmesi iÃ§in BOM ekleyen utf-8-sig kullanÄ±yoruz.
    with open(filepath, "w", encoding="utf-8-sig") as f:
        f.write("\n".join(lines))

    return filepath


# ===========================================================
# STREAMLIT ARAYÃœZÃœ
# ===========================================================

def main():
    """
    Streamlit tabanlÄ± gÃ¶rsel arayÃ¼z:
    - KullanÄ±cÄ±dan .mp4 video alÄ±r.
    - Hangi modeli/leri kullanacaÄŸÄ±nÄ± seÃ§tirir.
    - Analiz baÅŸlatÄ±ldÄ±ÄŸÄ±nda ilerleme Ã§ubuÄŸu gÃ¶sterir.
    - Analiz sonunda ihlal epizodlarÄ±nÄ± tablo ve CSV rapor olarak sunar.
    """
    st.set_page_config(page_title="Model KarÅŸÄ±laÅŸtÄ±rma ve Raporlama Sistemi", layout="wide")
    st.title("ğŸ“Š Model KarÅŸÄ±laÅŸtÄ±rma ve Raporlama Sistemi")
    st.markdown("**YOLO11n vs YOLO11s - Uyku ve GÃ¼venlik Ä°hlal Analizi (TensorRT FP16)**")

    # Video yÃ¼kleme
    uploaded_file = st.file_uploader("Analiz edilecek .mp4 videoyu seÃ§in", type=["mp4"])

    # Model seÃ§imi
    model_options = ["yolo11n", "yolo11s"]
    selected_models = st.multiselect(
        "Hangi modellerle analiz yapÄ±lsÄ±n?",
        options=model_options,
        default=model_options,  # varsayÄ±lan: ikisi de
        format_func=lambda k: MODEL_CONFIGS[k]["label"],
    )

    if not uploaded_file:
        st.info("LÃ¼tfen Ã¶nce bir .mp4 video dosyasÄ± yÃ¼kleyin.")
        return

    # YÃ¼klenen dosyayÄ± geÃ§ici bir yere kaydedelim
    temp_video_path = os.path.join("temp_video.mp4")
    with open(temp_video_path, "wb") as f:
        f.write(uploaded_file.read())

    if st.button("Analizi BaÅŸlat"):
        if not selected_models:
            st.warning("En az bir model seÃ§melisiniz.")
            return

        st.write("---")
        st.subheader("ğŸ” Analiz BaÅŸlÄ±yor")

        model_results: Dict[str, Dict[str, object]] = {}

        # Her seÃ§ili model iÃ§in ayrÄ± ayrÄ± analiz
        for m_key in selected_models:
            st.markdown(f"### {MODEL_CONFIGS[m_key]['label']} Analizi")
            episodes, avg_fps = analyze_video_with_model(temp_video_path, m_key)
            model_results[m_key] = {
                "episodes": episodes,
                "fps": avg_fps,
            }

            # Bu model iÃ§in ihlalleri tablo olarak gÃ¶ster
            if episodes:
                # Streamlit tabloda tam olarak 2 ondalÄ±k hane gÃ¶stermek iÃ§in
                # deÄŸerleri string formatÄ±na Ã§eviriyoruz.
                data = {
                    "Ä°hlal TÃ¼rÃ¼": [ep.violation_type for ep in episodes],
                    "BaÅŸlangÄ±Ã§ (sn)": [f"{ep.start_sec:.2f}" for ep in episodes],
                    "BitiÅŸ (sn)": [f"{ep.end_sec:.2f}" for ep in episodes],
                    "SÃ¼re (sn)": [f"{ep.duration:.2f}" for ep in episodes],
                }
                st.table(data)
            else:
                st.info("Bu model iÃ§in ihlal tespit edilmedi.")

            st.write(f"**Ortalama FPS:** {avg_fps:.2f}")
            st.write("---")

        # Her iki model iÃ§in performans karÅŸÄ±laÅŸtÄ±rmasÄ±
        st.subheader("âš–ï¸ Model Performans KarÅŸÄ±laÅŸtÄ±rmasÄ± (Ort. FPS)")
        # Ortalama FPS'leri tabloda da tam 2 ondalÄ±k hane ile gÃ¶stermek iÃ§in
        # string formatÄ±na Ã§eviriyoruz.
        perf_data = {
            "Model": [MODEL_CONFIGS[m]["label"] for m in model_results.keys()],
            "Ortalama FPS": [f"{model_results[m]['fps']:.2f}" for m in model_results.keys()],
        }
        st.table(perf_data)

        # Rapor dosyasÄ±nÄ± oluÅŸtur ve indirme linki ver
        st.subheader("ğŸ“ Rapor OluÅŸturma")
        report_path = save_report_csv("model_karsilastirma_raporu", model_results)
        st.success(f"Rapor oluÅŸturuldu: {report_path}")

        with open(report_path, "rb") as f:
            st.download_button(
                label="Raporu Ä°ndir (.csv)",
                data=f,
                file_name=os.path.basename(report_path),
                mime="text/csv",
            )


if __name__ == "__main__":
    main()

