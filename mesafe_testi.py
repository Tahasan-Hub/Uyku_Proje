import os
import time
import json
import cv2
import logging
import numpy as np
from ultralytics import YOLO
import mediapipe as mp
from datetime import datetime
import csv
import matplotlib.pyplot as plt
from tqdm import tqdm

from utils.core_logic import (
    CentroidTracker, eye_aspect_ratio, LEFT_EYE_IDX, RIGHT_EYE_IDX
)

# ===========================================================
# CONFIGURATION & LOGGING
# ===========================================================
CONFIG_PATH = "config.json"

def load_config():
    with open(CONFIG_PATH, "r") as f:
        return json.load(f)

config = load_config()

# KlasÃ¶r ayarlarÄ±
REPORT_DIR = config.get("output_report_dir", "raporlar")
os.makedirs(REPORT_DIR, exist_ok=True)

# Model & Cihaz ayarlarÄ±
selected_model_key = config.get("selected_model", "yolo11n")
model_info = config["model_configs"][selected_model_key]
MODEL_PATH = model_info["engine"] if os.path.exists(model_info["engine"]) else model_info["pt"]
DEVICE = config.get("device", 0)
CONF_THRESH = config.get("conf_threshold", 0.4)

# MediaPipe Setup
mp_face_mesh = mp.solutions.face_mesh

# ===========================================================
# Ã‡EKÄ°RDEK ANALÄ°Z FONKSÄ°YONU (PROGRESS BAR EKLENDÄ°)
# ===========================================================

def analyze_video_simulated(video_path, distance_meters):
    """
    Bir videoyu fiziksel mesafe-Ã¶lÃ§ek formÃ¼lÃ¼ne gÃ¶re simÃ¼le eder.
    """
    if not os.path.exists(video_path):
        return None

    scale = 1.0 / distance_meters

    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    if total_frames == 0:
        cap.release()
        return None

    model = YOLO(MODEL_PATH)
    face_mesh = mp_face_mesh.FaceMesh(
        static_image_mode=False,
        max_num_faces=1,
        refine_landmarks=True,
        min_detection_confidence=0.5
    )

    person_detected_frames = 0
    ear_success_frames = 0
    start_time = time.time()

    # TQDM Ä°LERLEME Ã‡UBUÄU (%) - Ä°ndirme gibi ilerleme Ã§ubuÄŸu
    pbar = tqdm(total=total_frames, desc=f"  Analiz {distance_meters}m", unit="kare", leave=False)

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        h, w = frame.shape[:2]

        # SÄ°MUASYON: Mesafe bazlÄ± Ã§Ã¶zÃ¼nÃ¼rlÃ¼k dÃ¼ÅŸÃ¼rme
        if distance_meters > 1.0:
            new_w, new_h = max(1, int(w * scale)), max(1, int(h * scale))
            small = cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_AREA)
            sim_frame = cv2.resize(small, (w, h), interpolation=cv2.INTER_NEAREST)
        else:
            sim_frame = frame

        # YOLO Tespiti
        results = model(sim_frame, conf=CONF_THRESH, classes=[0], device=DEVICE, verbose=False)
        person_boxes = results[0].boxes if results[0].boxes is not None else []
        
        if len(person_boxes) > 0:
            person_detected_frames += 1
            
            # EAR BaÅŸarÄ±sÄ±
            rgb_frame = cv2.cvtColor(sim_frame, cv2.COLOR_BGR2RGB)
            face_results = face_mesh.process(rgb_frame)
            
            if face_results.multi_face_landmarks:
                ear_success_frames += 1

        pbar.update(1) # Ã‡ubuÄŸu % olarak ilerlet

    pbar.close() # Ã‡ubuÄŸu bitir
    total_processing_time = time.time() - start_time
    cap.release()
    face_mesh.close()

    detection_rate = (person_detected_frames / total_frames) * 100
    ear_success_rate = (ear_success_frames / person_detected_frames * 100) if person_detected_frames > 0 else 0
    fps = total_frames / total_processing_time if total_processing_time > 0 else 0

    return {
        "distance": distance_meters,
        "total_frames": total_frames,
        "detected_frames": person_detected_frames,
        "ear_frames": ear_success_frames,
        "detection_rate": round(detection_rate, 2),
        "ear_success_rate": round(ear_success_rate, 2),
        "total_time": round(total_processing_time, 2),
        "fps": round(fps, 2)
    }

# ===========================================================
# GÃ–RSELLEÅTÄ°RME FONKSÄ°YONU
# ===========================================================

def generate_performance_plot(all_results, timestamp):
    """Mesafeye gÃ¶re % BaÅŸarÄ± grafiÄŸi oluÅŸturur."""
    distances = [res['distance'] for res in all_results]
    det_rates = [res['detection_rate'] for res in all_results]
    ear_rates = [res['ear_success_rate'] for res in all_results]
    fps_values = [res['fps'] for res in all_results]

    plt.style.use('ggplot')
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 10))
    
    # % BAÅARI GRAFÄ°ÄÄ°
    ax1.plot(distances, det_rates, marker='o', label='Kisi Tespit %', color='#3498db', linewidth=3)
    ax1.plot(distances, ear_rates, marker='s', label='EAR Basari %', color='#2ecc71', linewidth=3)
    ax1.set_title('Mesafe BazlÄ± % BaÅŸarÄ± Analizi', fontsize=14, pad=15)
    ax1.set_xlabel('Mesafe (Metre)')
    ax1.set_ylabel('BaÅŸarÄ± OranÄ± (%)')
    ax1.set_xticks(distances)
    ax1.set_ylim(0, 105)
    ax1.legend(loc='lower left')
    ax1.grid(True, alpha=0.3)

    # FPS VE ZAMAN ANALÄ°ZÄ°
    ax2.bar(distances, fps_values, color='#e67e22', alpha=0.7, label='FPS PerformansÄ±')
    ax2.set_title('Ä°ÅŸlem HÄ±zÄ± (FPS) Analizi', fontsize=14, pad=15)
    ax2.set_xlabel('Mesafe (Metre)')
    ax2.set_ylabel('Saniyedeki Kare (FPS)')
    ax2.set_xticks(distances)
    ax2.legend()

    plt.tight_layout()
    plot_file = os.path.join(REPORT_DIR, f"Mesafe_Performans_Grafigi_{timestamp}.png")
    plt.savefig(plot_file, dpi=150)
    plt.close()
    return plot_file

# ===========================================================
# MAIN ENTRY POINT
# ===========================================================

def main():
    print("\n" + "â•"*85)
    print(" PROFESYONEL MESAFE BAZLI PERFORMANS ANALÄ°Z SÄ°STEMÄ° ".center(85))
    print("â•"*85 + "\n")

    source_video = "uyku_testi.mp4" 

    if not os.path.exists(source_video):
        print(f"âŒ HATA: '{source_video}' kaynak dosyasÄ± bulunamadÄ±!")
        return

    test_distances = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    all_results = []
    
    print(f"ğŸ“‚ Kaynak Video: {source_video}")
    print(f"ğŸ¤– Model: {MODEL_PATH} | âš™ï¸ Cihaz: {DEVICE}\n")

    for d in test_distances:
        metrics = analyze_video_simulated(source_video, d)
        if metrics:
            all_results.append(metrics)
            print(f"âœ… {d}m Analiz TamamlandÄ±: Tespit %{metrics['detection_rate']} | EAR %{metrics['ear_success_rate']} ")
        else:
            print(f"âŒ {d}m Analiz BaÅŸarÄ±sÄ±z! ")

    # Ekrana Tablo Basma
    print("\n" + "â•”" + "â•"*81 + "â•—")
    print("â•‘" + " TEST SONUÃ‡LARI Ã–ZET TABLOSU ".center(81) + "â•‘")
    print("â• " + "â•"*8 + "â•¤" + "â•"*18 + "â•¤" + "â•"*17 + "â•¤" + "â•"*15 + "â•¤" + "â•"*17 + "â•£")
    print(f"â•‘ {'Mesafe':<6} â”‚ {'Ä°ÅŸlenen Kare':<16} â”‚ {'Tespit OranÄ±':<15} â”‚ {'EAR BaÅŸarÄ±':<13} â”‚ {'HÄ±z (FPS)':<15} â•‘")
    print("â•Ÿ" + "â”€"*8 + "â”¼" + "â”€"*18 + "â”¼" + "â”€"*17 + "â”¼" + "â”€"*15 + "â”¼" + "â”€"*17 + "â•¢")
    for res in all_results:
        kare_bilgisi = f"{res['detected_frames']}/{res['total_frames']}"
        print(f"â•‘ {res['distance']:>5}m   â”‚ {kare_bilgisi:<16} â”‚ %{res['detection_rate']:<14} â”‚ %{res['ear_success_rate']:<13} â”‚ {res['fps']:<15} â•‘")
    print("â•š" + "â•"*8 + "â•§" + "â•"*18 + "â•§" + "â•"*17 + "â•§" + "â•"*15 + "â•§" + "â•"*17 + "â•")

    # RaporlarÄ± Kaydetme
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    plot_file = generate_performance_plot(all_results, timestamp)
    print(f"\nğŸ“Š Performans grafiÄŸi (PNG) kaydedildi: {plot_file}")

    report_file = os.path.join(REPORT_DIR, f"Mesafe_Performans_Raporu_{timestamp}.csv")
    try:
        with open(report_file, mode='w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=all_results[0].keys(), delimiter=';')
            writer.writeheader()
            writer.writerows(all_results)
        print(f"ğŸ“„ DetaylÄ± CSV raporu kaydedildi: {report_file}")
    except Exception as e:
        print(f"âš ï¸ Rapor kaydedilemedi: {e}")

if __name__ == "__main__":
    main()
